\documentclass{pbml}
\usepackage{natbib}
\usepackage{thanks-nostar}
\usepackage{subfig}
%\setlength\titlebox{3in}
%\usepackage{naaclhlt2010}
%\usepackage{draftcopy}[all,draft,light,timestamp]
%\usepackage{draftwatermark}
%\usepackage{datetime}
%\usepackage{times}
%\usepackage{latexsym}
%\usepackage{url}
\usepackage{multirow}
\usepackage{amsmath}
\newcommand\bmmax{1}
\usepackage{bm}
\usepackage{fontspec}
%\usepackage{todonotes}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[colorlinks,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{
width=7cm,
compat=1.3,
colormap name=blackwhite
%,bar cycle list name=black white
}
%\SetWatermarkLightness{0.95}
%\SetWatermarkLightness{1}
%\SetWatermarkText{\dmyydate \today, \currenttime}
\DeclareMathOperator*{\argmax}{arg\,max}

\defaultfontfeatures{Mapping=tex-text}

%\fontspec{TeX Gyre Pagella}

\begin{document}

\title{Better Splitting Algorithms for Parallel Corpus Processing}

\institute{label1}{Air Force Research Laboratory\\
  Human Effectiveness Directorate\\
  Wright-Patterson AFB, OH USA
}


\author{
  firstname=Lane,
  surname=Schwartz,
  institute=label1,
  corresponding=yes,
  email={Lane.Schwartz@wpafb.af.mil},
  address={2255 H St, Dayton, OH 45433, USA}
}


\PBMLmaketitle

%%%%%%%%%%%%%%%%%%%%%%%
% Let's find some space
%\renewcommand{\topfraction}{0.9}
%\renewcommand{\bottomfraction}{0.8}
%\renewcommand{\textfraction}{0.05}
%\renewcommand{\dbltopfraction}{0.9}
%\renewcommand{\dblfloatpagefraction}{0.9}
%\setcounter{topnumber}{10}
%\setcounter{bottomnumber}{10}
%\setcounter{totalnumber}{10}
%\setcounter{dbltopnumber}{10}
%
%%%%%%%%%%%%%%%%%%%%%%%

%\fontspec
%[ Extension      = .otf ,
%  UprightFont    = *-regular ,
%  BoldFont       = *-bold ,
%  ItalicFont     = *-italic ,
%  BoldItalicFont = *-bolditalic
%]{TeX Gyre Pagella}
\fontspec{TeX Gyre Pagella}

%\fontspec[AutoFakeBold=1.5]{TeX Gyre Pagella}

\begin{abstract}
Each iteration of minimum error rate training involves re-translating a development set. Distributing this work across computational nodes can speed up translation time, but in practice some parts may take much longer to complete than others, leading to computational slack time. To address this problem, we develop three novel algorithms for distributing translation tasks in a parallel computing environment, drawing on research in parallel machine scheduling. We present results showing a substantial speedup in overall decoding time.
\end{abstract}



\section{Introduction}

The task of translation involves translating a source language document $\mathbf{f}$ into target language $\mathbf{e}$. Most popular statistical translation techniques select the best translation $\hat{e}$ for source sentence $f$ according to a linear combination of models $\bm{\phi}$ using a set of model weights $\bm{\lambda}$ \citep{ochney02}. 

\begin{equation}
\hat{e} = \argmax_e \sum_i \lambda_i \phi_i(e,f)
\label{eq:smt}
\end{equation}


Values for $\bm{\lambda}$ are obtained by optimizing an objective function such as BLEU \citep{papinenietal01} against a development set, most commonly using minimum error rate training (MERT) \citep{och03}. Each iteration of MERT requires this development set to be re-translated using a new set of $\bm{\lambda}$ weights. MERT is one of the slowest components in a typical machine translation training pipeline, and translating the development set is nearly always the slowest step in MERT. We now examine techniques for speeding up the translation process by splitting a source document into parts and distributing the translation of those parts across parallel computational nodes. 

Ideally, all parts should take the same amount of time to translate. While naive splitting techniques reduce the time required for each translation iteration by splitting the work between $n$ computational nodes, in practice some parts may take much longer to complete than others. This can lead to significant computational slack time.
%
To address this problem, we develop three novel algorithms for splitting translation tasks in a parallel computing environment, drawing on research in parallel machine scheduling.





\section{Related Work}


Research into parallel machine scheduling problems constitutes a wide and well-studied field, ranging through various disciplines of engineering, manufacturing, and management in addition to computer science and applied mathematics \citep{ChengSin90}, 
spanning a wide range of scheduling techniques \citep{PanwalkarIskander77}.
%\citet{PanwalkarIskander77} present a survey of over 100 published scheduling techniques.

We now briefly examine the existing research most relevant to our task. \citet{Hu61} and Graham \citeyearpar{Graham66,Graham69} develop various list scheduling algorithms. This family of algorithms prioritizes jobs into a queue, then assigns jobs to machines in queue order. This approach attempts to evenly balance the load on each execution host \citep{DeMorton80,ChengSin90}. 
%Of the techniques which we examine in this work, Algorithms \ref{alg:naive}, \ref{alg:words}, and \ref{alg:times} fall into this category.
Both Algorithm \ref{alg:naive} below and the techniques we develop in Section \ref{sec:better} fall into this family of algorithms.

\begin{algorithm}
\caption{Split input text into $n$ parts such that each part contains the same number of lines. In cases where the total number of lines is not evenly divisible by $n$, the last part will contain fewer lines than each of the other parts.}
\begin{algorithmic}
\fontspec{TeX Gyre Pagella}
\Function{\fontspec{TeX Gyre Pagella}\textsc{Naive-Split}}{$n$,input}
\State $s \gets $ input.length
\State $\ell \gets \lceil s / n\rceil$
\For {$p \gets 0 \ldots (n-1)$}
\State $i \gets \ell \times p$
\For {$j \gets i \ldots \min(i+\ell-1$,$s-1)$}
%\If{$j < \ell$}
\State output[$p$].append(input[$j$])
%\Else
%\State \textbf{break}
%\EndIf
\EndFor
\EndFor
\State \textbf{return} output
\EndFunction
\end{algorithmic}
\label{alg:naive}
\end{algorithm}

While the models in Equation \ref{eq:smt} could, in theory, condition on previously translated sentences, in practice virtually no widely used models do so. It is therefore very straightforward to split the data into $n$ parts, and translate each part independently on $n$ computational nodes. 




%In the general case, scheduling algorithms must determine where and when to schedule the execution of incoming jobs, based on machine factors such as the number of available machines, processing speed, memory availability, and the homogeneity or heterogeneity of available machines; and job factors such as arrival time, estimated work time, deadline, and whether or not jobs are preemptive. Preemptive jobs can be suspended during execution and later resumed on the a potentially different machine.

%Since we are interested in minimizing the overall runtime required to translate a source document (multiple times in the case of MERT), we are able to focus the range of above factors. The jobs in our task are treated as non-preemptive. Unlike the online variants of machine scheduling, all jobs in our task arrive simultaneously. These jobs have no explicit deadline. We further make the simplifying assumption that all execution hosts will be homogenous, with identical hardware configurations. 




\begin{figure*}
\centering
\begin{tikzpicture}
\begin{axis}[
xmode=normal,
ymode=normal,
xtick={100,200,300,400,500,600,700,800},
ytick={0,50,100,150,200,250,300},
tick label style={font=\tiny},
xlabel=Sentence Number,
ylabel=Sentence Length,
ymin=0,
xmin=0,
xmax=883,
xtick pos=left,
ytick pos=left,
xtick align=outside,
ytick align=outside,
ybar,
bar width=0.5pt,
cycle list={fill=black},
width=13cm,
height=5cm
]
%\input{sentence_lengths}
\input{figures/sentence_lengths/Corpus.nist08_dev/plot.tex}
\end{axis}
\end{tikzpicture}
\caption{Sentence length (in words) of sentences from the NIST OpenMT 2008 Urdu-English task.}
\label{fig:sentence-length}
\end{figure*}


% \begin{figure*}[!h]
% \centering
% \begin{tikzpicture}
% \begin{axis}[
% xmode=normal,
% ymode=normal,
% xtick={100,200,300,400,500,600,700,800},
% ytick={0,5,10,15},
% tick label style={font=\tiny},
% %xlabel=Sentence Number,
% ylabel=Translation Time,
% ymin=0,
% xmin=0,
% xmax=883,
% xtick pos=left,
% ytick pos=left,
% xtick align=outside,
% ytick align=outside,
% ybar,
% bar width=0.5pt,
% cycle list={fill=black},
% width=13cm,
% height=5cm
% ]
% \input{sentence_times}
% \end{axis}
% \end{tikzpicture}
% \caption{Translation decoding time (in seconds) of each sentence in the development set of the NIST OpenMT 2008 Urdu-English task for a decoder configured using a 5-gram language model.}
% \label{fig:sentence-times}
% \end{figure*}

\begin{figure*}[!p]
\centering
\subfloat[Algorithm \ref{alg:naive} --- \textsc{Naive-Split}]{
\begin{tikzpicture}
\begin{axis}[
xmode=normal,
ymode=normal,
xtick={0,8,16,24,32,40,48,56,64},%data,%{100,200,300,400,500,600,700,800},
ytick={0,10,20,30,40,50,60,70,80},
tick label style={font=\tiny},
%xlabel=Split Part Number,
ylabel=Translation Time,
ymin=0,
ymax=80,
xmin=0,
xmax=64,
xtick pos=left,
ytick pos=left,
xtick align=outside,
ytick align=outside,
ybar,
bar width=5pt,
cycle list={fill=black},
width=13cm,
height=4cm
]
%\input{split/time_sum.64}
\input{figures/parts_time_summary/Algorithm.naive+Corpus.nist08_dev+Parts.64/plot.tex}
\end{axis}
\end{tikzpicture}
%\caption{Total time (in seconds) for each part when split using Algorithm \ref{alg:naive}.}
%\caption{Translation decoding time (in seconds) of sentences from the NIST OpenMT 2008 Urdu-English task with a decoder configured using a 5-gram language model.}
\label{fig:plot-naive}
%\end{figure*}
}

\subfloat[Algorithm \ref{alg:histogram} --- \textsc{Histogram-Split}]{
%\begin{figure*}[!p]
%\centering
\begin{tikzpicture}
\begin{axis}[
xmode=normal,
ymode=normal,
xtick={0,8,16,24,32,40,48,56,64},%data,%{100,200,300,400,500,600,700,800},
ytick={0,10,20,30,40,50,60,70,80},
tick label style={font=\tiny},
%xlabel=Split Part Number,
ylabel=Translation Time,
ymin=0,
ymax=80,
xmin=0,
xmax=64,
xtick pos=left,
ytick pos=left,
xtick align=outside,
ytick align=outside,
ybar,
bar width=5pt,
cycle list={fill=black},
width=13cm,
height=4cm
]
%\input{split/histogram_time_sum.64}
\input{figures/parts_time_summary/Algorithm.histogram+Corpus.nist08_dev+Parts.64/plot.tex}
\end{axis}
\end{tikzpicture}
\label{fig:plot-histogram}
%\caption{Total time (in seconds) for each part when split using Algorithm \ref{alg:histogram}.}
%\caption{Translation decoding time (in seconds) of sentences from the NIST OpenMT 2008 Urdu-English task with a decoder configured using a 5-gram language model.}
%\label{fig:histogram-split-times}
}
%\end{figure*}

\subfloat[Algorithm \ref{alg:words} --- \textsc{Words-Split}]{
%\begin{figure*}[!p]
%\centering
\begin{tikzpicture}
\begin{axis}[
xmode=normal,
ymode=normal,
xtick={0,8,16,24,32,40,48,56,64},%data,%{100,200,300,400,500,600,700,800},
ytick={0,10,20,30,40,50,60,70,80},
tick label style={font=\tiny},
%xlabel=Split Part Number,
ylabel=Translation Time,
ymin=0,
ymax=80,
xmin=0,
xmax=64,
xtick pos=left,
ytick pos=left,
xtick align=outside,
ytick align=outside,
ybar,
bar width=5pt,
cycle list={fill=black},
width=13cm,
height=4cm
]
%\input{split/histogram_time_sum.64}
\input{figures/parts_time_summary/Algorithm.words+Corpus.nist08_dev+Parts.64/plot.tex}
\end{axis}
\end{tikzpicture}
\label{fig:plot-words}
%\caption{Total time (in seconds) for each part when split using Algorithm \ref{alg:words}.}
%\caption{Translation decoding time (in seconds) of sentences from the NIST OpenMT 2008 Urdu-English task with a decoder configured using a 5-gram language model.}
%\label{fig:words-split-times}
%\end{figure*}
}

\subfloat[Algorithm \ref{alg:times} --- \textsc{Times-Split}]{
%\begin{figure*}[!p]
%\centering
\begin{tikzpicture}
\begin{axis}[
xmode=normal,
ymode=normal,
xtick={0,8,16,24,32,40,48,56,64},%data,%{100,200,300,400,500,600,700,800},
ytick={0,10,20,30,40,50,60,70,80},
tick label style={font=\tiny},
%xlabel=Split Part Number,
ylabel=Translation Time,
ymin=0,
ymax=80,
xmin=0,
xmax=64,
xtick pos=left,
ytick pos=left,
xtick align=outside,
ytick align=outside,
ybar,
bar width=5pt,
cycle list={fill=black},
width=13cm,
height=4cm
]
%\input{split/histogram_time_sum.64}
\input{figures/parts_time_summary/Algorithm.time+Corpus.nist08_dev+Parts.64/plot.tex}
\end{axis}
\end{tikzpicture}
\label{fig:plot-time}
}
\caption{Total translation time (in \textbf{seconds}) for each part when data from the NIST OpenMT 2008 Urdu-English task is split into 64 parts using each of four algorithms.}
%\caption{Translation decoding time (in seconds) of sentences from the NIST OpenMT 2008 Urdu-English task with a decoder configured using a 5-gram language model.}
\label{fig:time-split-times}
\end{figure*}


\section{Better Splitting Algorithms}
\label{sec:better}

We begin by examining the development set for the NIST OpenMT 2008 Urdu-English task. When tuning the model weights $\bm{\lambda}$, this development set will be translated numerous times. We observe in Figure \ref{fig:sentence-length} that the number of words in each sentence varies widely and unevenly throughout the corpus. %This is notable in that when this corpus is split using Algorithm \ref{alg:naive}, 

%Scripts included with Moses \citep{moses} do exactly that, simply splitting the data into $p$ arbitrary parts (Algorithm \ref{alg:naive}) of $\ell$ or fewer lines each. 
Using Algorithm \ref{alg:naive}, scripts included with Moses \citep{moses} split the corpus into $n$ parts of of $\ell$ or fewer lines each; $\ell$ is the smallest integer greater than or equal to $s/n$, where $s$ is the total number of input sentences. The first $\ell$ lines comprise the first part, the next $\ell$ lines comprise the second part, and so on. Thus, each part contains exactly $\ell$ lines, with the possible exception of the last part, which contains fewer than $\ell$ lines when $s$ is not evenly divisible by $n$.

Figure \ref{fig:plot-naive} shows the amount of time taken to translate each part of the development set, split using Algorithm \ref{alg:naive} into 64 parts, using Moses configured with a 5-gram language model. 
We observe that the shape of Figure \ref{fig:plot-naive} generally matches that of Figure \ref{fig:sentence-length}.
%Because Algorithm \ref{alg:naive} partitions contiguous sentences together, and because phrase-based decoding with a finite distortion limit takes linear time, it is not surprising to see that the shape of the graph in Figure \ref{fig:plot-naive} generally matches that of \ref{fig:sentence-length}. 
There is substantial variance in translation time between the parts in Figure \ref{fig:plot-naive}, with some parts taking nearly 80 seconds and many others finishing in well under 10 seconds. We observe that this disparity is largely due to an imbalance of short versus long sentences between the parts. Because short sentences take less time to translate than long sentences, parts assigned mostly short sentences finish much faster than parts that are assigned many longer sentences. 

%Algorithm \ref{alg:naive} first calculates 

%In examining the logs of various translations jobs split using Algorithm \ref{alg:naive}, we observe that slack time results primarily from situations where some jobs are assigned a disproportionate number of short sentences. 
%



\begin{algorithm}[!h]
\caption{Split input text into $n$ parts to balance the histograms of line lengths for all parts.}
\begin{algorithmic}
\fontspec{TeX Gyre Pagella}
\Function{\fontspec{TeX Gyre Pagella}\textsc{Histogram-Split}}{$n$,input}
\For {$i \gets 0 \ldots ($ input.length $-1)$}
\State sentence[$i$].length $\gets$ input[$i$].length
\State sentence[$i$].index $\gets i$
\EndFor
\State \Call{Sort}{sentence} $\left\{|x,y|\ x.\mbox{length}\Leftrightarrow y.\mbox{length}\right\}$ 
\State \Comment{Sort sentences by length}
\State $p \gets n$
\For {$i \gets 0 \ldots ($input.length $-1)$}
\If {$p < n$}
\State $p \gets p+1$
\Else
\State $p \gets 0$
\EndIf
\State output[$p$].append(input[sentence[$i$].index])
\EndFor
\State \textbf{return} output
\EndFunction
\end{algorithmic}
\label{alg:histogram}
\end{algorithm}


%While the models in Equation \ref{eq:smt} could, in theory, condition on previously translated sentences, in practice virtually no widely used models do so. It is therefore very straightforward to split the data into $p$ parts, and translate each part independently on $p$ computational nodes. The question then arises - how should the data be split? Algorithm \ref{alg:naive} naively splits the data into $p$ arbitrary parts such that each part contains the same number of lines. This algorithm is currently implemented and distributed in Moses \citep{moses}.

To remedy this imbalance, we propose Algorithm \ref{alg:histogram}. 
%
Prior to splitting the data into parts, Algorithm \ref{alg:histogram} begins by examining the number of words in each sentence.
%
Sentences are sorted according to length, then assigned in turns to parts. 
%
This round-robin distribution of sentences into parts results in the sentence length histograms for each part being approximately equal. 
%
While Algorithm \ref{alg:histogram} attempts to balance short and long sentences across parts, we nevertheless observe non-trivial imbalance in translation times across parts in Figure \ref{fig:plot-histogram}.

% \begin{figure*}
% \centering
% \begin{tikzpicture}
% \begin{axis}[
% xmode=normal,
% ymode=normal,
% xtick={10,20,30,40,50,100,150,200,250,300},
% ytick={1,5,10,15,20,25,30,35},
% tick label style={font=\tiny},
% xlabel=Sentence Length (in words),
% ylabel=Number of Sentences,
% ymin=0,
% xmin=0,
% xtick pos=left,
% ytick pos=left,
% xtick align=outside,
% ytick align=outside,
% ybar,
% bar width=0.5pt,
% cycle list={fill=black},
% width=13cm,
% height=7cm
% ]
% \input{devset.histogram.part1}
% \end{axis}
% \end{tikzpicture}
% \caption{Sentence length histogram for the development set of the NIST OpenMT 2008 Urdu-English task.}
% \label{fig:histogram}
% \end{figure*}

%While Algorithm \ref{alg:histogram} attempts to balance short and long sentences across parts, this algorithm can still lead to sizeable slack time in cases with severe length imbalances between sentences. Development set for the NIST OpenMT 2008 Urdu-English task 
%
%we may be able to achieve even more balanced runtimes by balancing the total number of words in each part. 



\begin{algorithm}
\caption{Split input text into $n$ parts to balance the number of words for all parts.}
\begin{algorithmic}
\fontspec{TeX Gyre Pagella}
\Function{\fontspec{TeX Gyre Pagella}\textsc{Words-Split}}{$n$,input}
\For {$i \gets 0 \ldots ($ input.length $-1)$}
\State sentence[$i$].length $\gets$ input[$i$].length
\State sentence[$i$].index $\gets i$
\EndFor
\State \Call{Sort}{sentence} $\left\{|x,y|\ y.\mbox{length}\Leftrightarrow x.\mbox{length}\right\}$ 
\State \Comment{Sort sentences by length, in reverse order}
\For {$i \gets 0 \ldots ($ input.length $-1)$}
\State $p \gets$ \Call{Least}{words}
\State \Comment{Find partition with fewest words}
\State output[$p$].append(input[sentence[$i$].index])
\State words[$p$] $\gets$\hspace{0em}words[$p$] $+$ sentence[$i$].length%
%\State words[$p$]\hspace{0em}$\gets$\hspace{0em}words[$p$]\hspace{0em}$+$\hspace{0em}sentence[$i$].length%
\EndFor
\State \textbf{return} output
\EndFunction
\end{algorithmic}
\label{alg:words}
\end{algorithm}
%
%

%
%
To improve this remaining imbalance, we propose Algorithm \ref{alg:words}.
%
In Algorithm \ref{alg:words}, sentences are sorted by length into a queue, with longest sentences at the head of the queue.
%Algorithm \ref{alg:words} counts the number of words in each sentence to be translated. Sentences are then ordered by this length, in reverse order. Initially, no computation slots have assigned translation jobs. 
%
Initially, no sentences have been assigned to any part.
%
The longest sentence, at the head of the queue, is assigned first to a part. As each sentence is assigned to a part, the total number of words assigned to that part is recorded. 
%
Each subsequent sentence is removed from the queue and assigned to the part with 
%
%
the least work assigned to it, as measured by number 
%
of words.
%
In Figure \ref{fig:plot-words}, we observe that most of the imbalance in translation times across parts has been resolved.




When assigning sentences to jobs, we would ideally like to know how long each sentence will take to process. Algorithms \ref{alg:histogram} and \ref{alg:words} use the number of words in each sentence as a proxy for processing time. During MERT, the same set of development sentences are translated multiple times. Since each decoding process differs only by the $\bm{\lambda}$ weights used, it is reasonable to expect little variation in decoding runtime for any given sentence across all MERT runs. With this in mind, we record the time required to translate each sentence during the first iteration of MERT. In subsequent iterations, Algorithm \ref{alg:times} uses the time recorded to translate a sentence as an estimate of the time it will take to translate that sentence again. Algorithm \ref{alg:times} differs from Algorithm \ref{alg:words} by sorting using these times instead of sentence length.
%
We see in Figure \ref{fig:plot-time} that the time imbalance between parts is virtually non-existent, with all times now within 0.01 seconds of each other.

%\todo[inline]{Describe Algorithm \ref{alg:times}. \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ }

\begin{algorithm}
\caption{Split input text into $n$ parts to balance the estimated translation time of all parts.}
\begin{algorithmic}
\fontspec{TeX Gyre Pagella}
\Function{\fontspec{TeX Gyre Pagella}\textsc{Times-Split}}{$n$,input,estimate}
\For {$i \gets 0 \ldots ($ input.length $-1)$}
\State sentence[$i$].time $\gets$ estimate[$i$]
\State sentence[$i$].index $\gets i$
\EndFor
\State \Call{Sort}{sentence} $\left\{|x,y|\ y.\mbox{time}\Leftrightarrow x.\mbox{time}\right\}$ 
\State \Comment{Sort sentences by time, in reverse order}
\For {$i \gets 0 \ldots ($ input.length $-1)$}
\State $p \gets$ \Call{Least}{times}
\State \Comment{Find partition with least time}
\State output[$p$].append(input[sentence[$i$].index])
\State times[$p$] $\gets$ times[$p$] $ + $ sentence[$i$].time
\EndFor
\State \textbf{return} output
\EndFunction
\end{algorithmic}
\label{alg:times}
\end{algorithm}

\section{Experimental Configuration}

To observe the effects of splitting algorithms on decoding speed, we translated the NIST OpenMT 2008 development set of Urdu-English data using Moses in a parallel computing cluster, distributing work using the Sun Grid Engine. We ran two decoding setups: a standard configuration using a 5-gram language model, and a much slower syntactic LM configuration following \citet{schwartzetal11}. 

Figure \ref{fig:time-split-times} shows the per-part translation times for all parts of the development set when $n=64$. 
%
In Figure \ref{fig:maxspeed}, we examine the per-part translation times for only the slowest of $n$ translation jobs in each configuration for various values of $n$, ranging from 2--512.
%
In all configurations, we see that Algorithm \ref{alg:times} provides the fastest performance.
%We observe the same trend found in Figure \ref{fig:time-split-times}, 

Another metric to use in examining our algorithms is total computational slack time.
%
During MERT, computational slack time arises when some parts of the development set finish translating faster than others.
%
Figure \ref{fig:minmaxspeed} lists the decoding times of the fastest and slowest translation jobs for parts split using each of the four algorithms for various values of $n$, ranging from 2--512.
%
We see the total cumulative slack time for each of these conditions in Figure \ref{fig:slack}.

%Using Algorithm \ref{alg:naive}, the runtimes of the slowest of $n$ translation jobs in each configuration are illustrated in Figure \ref{fig:maxspeed} for various values of $n$ (under the label \textsc{Naive-Split}). Figure \ref{fig:minmaxspeed} shows that in all cases, there is a significant difference between the fastest and slowest translation job, leading to computational slack time (Figure \ref{fig:slack}).

%
%
%
%In nearly all translation models, each sentence is translated independently 
%
%\todo[inline]{Describe Algorithm \ref{alg:words}. \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ }
%
%
%Slack time is essentially eliminated in nearly all ($n<256$) conditions. 
%
%\footnote{Where slack time remains, $nabcheat=(256,512)$, a few jobs were each assigned a single long sentence that took longer to translate than the other jobs which were assigned multiple shorter sentences.}


\begin{figure*}[p]
\centering
\subfloat[Decoding times in \textbf{seconds} for decoder configured using a 5-gram language model.]{
%%%%%%%%%%%%%%%%%%%%%%% 
% Begin subfloat
%%%%%%%%%%%%%%%%%%%%%%%
\begin{tikzpicture}
\begin{axis}[
xmode=log,
ymode=normal,
xtick pos=left,
xtick=data,
ytick=data,
log basis x=2,
xticklabels={8,16,32,64,128,256,512},
ytick={160,150,140,130,120,110,100,90,80,70,60,50,40,30,20,10},
tick label style={font=\tiny},
xlabel=Split Size ($n$),
ylabel=Decode Time (Seconds),
ymin=0,
%enlarge x limits=0.5,
%scale only axis=false,
%axis equal=false,
%legend style={
%	at={(0.5,-0.15)},
%	anchor=north,legend columns=-1
%},
%ybar=0pt,
width=13cm,
height=7cm,
ybar,
bar width=7pt,
cycle list={fill=gray!15!blue!15,fill=gray!50!orange!50,fill=gray!70!green!70,fill=gray!100}
%bar shift=3pt
%ybar interval=0.7
]
%
\input{ngram/ngram.naive-Maximum_times}
\input{ngram/ngram.histogram-Maximum_times}
\input{ngram/ngram.words-Maximum_times}
\input{ngram/ngram.time-Maximum_times}
%
\legend{{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 1: \textsc{Naive-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 2: \textsc{Histogram-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 3: \textsc{Words-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 4: \textsc{Times-Split}}}
\end{axis}
\end{tikzpicture}
}
%\caption{\fontspec{TeX Gyre Pagella}Decoding times (in {\textbf{seconds}}) for the slowest translation job in a translation task split into $n$ decoding jobs using various splitting algorithms (\textsc{Naive-Split}, \textsc{Histogram-Split}, \textsc{Words-Split}, and \textsc{Times-Split}) for a phrase-based decoder configured using a 5-gram language model.}
%\label{fig:maxspeed}
%\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%% 
% End subfloat
%%%%%%%%%%%%%%%%%%%%%%%

%\qquad
%
%%%%%%%%%%%%%%%%%%%%%%% 
% Begin subfloat
%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure*}[p]
%\centering
\subfloat[Decoding times in \textbf{hours} for decoder configured using a syntactic language model (Schwartz et al., 2011) in addition to a 5-gram language model.]{
\begin{tikzpicture}%[scale=2]
\begin{axis}[
xmode=log,
ymode=normal,
xtick pos=left,
xtick=data,
ytick=data,
log basis x=2,
xticklabels={8,16,32,64,128,256,512},
ytick={130,120,110,100,90,80,70,60,50,40,30,20,10},
tick label style={font=\tiny},
xlabel=Split Size ($n$),
ylabel=Decode Time (Hours),
ymin=0,
%ybar=0pt,
ybar,
bar width=7pt,
%bar shift=0pt,
width=13cm,
height=7cm,
%cycle list name=black white
%colormap name=bluered
%cycle list={fill={blue!80!red!30}, fill=red!66, fill=yellow!33, black}
%cycle list={fill=blue!30!white,fill=red!60!white,fill=brown!90!white,fill=black}
%cycle list={fill=blue!30!white,fill=red!30!white,fill=brown!30!white,fill=grey}
%cycle list={fill=gray!25,fill=gray!50,fill=gray!75,fill=gray!100}
cycle list={fill=gray!15!blue!15,fill=gray!50!orange!50,fill=gray!70!green!70,fill=gray!100}
%cycle list name=color
]
%
\input{hhmm/hhmm.naive-Maximum_times}
\input{hhmm/hhmm.histogram-Maximum_times}
\input{hhmm/hhmm.words-Maximum_times}
\input{hhmm/hhmm.time-Maximum_times}
%
%\legend{Naive,Histogram,Words,Oracle}
\legend{{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 1: \textsc{Naive-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 2: \textsc{Histogram-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 3: \textsc{Words-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 4: \textsc{Times-Split}}}
\end{axis}
\end{tikzpicture}
}
%%%%%%%%%%%%%%%%%%%%%%% 
% End subfloat
%%%%%%%%%%%%%%%%%%%%%%%
%\caption{\fontspec{TeX Gyre Pagella}Decoding times (in \textbf{hours}) for the slowest translation job in a translation task split into $n$ decoding jobs using various splitting algorithms (\textsc{Naive-Split}, \textsc{Histogram-Split}, \textsc{Words-Split}, and \textsc{Times-Split}) for a phrase-based decoder configured using a syntactic language model (Schwartz et al., 2011) in addition to a 5-gram language model.}
\caption{\fontspec{TeX Gyre Pagella}Decoding times for the slowest translation job in a translation task split into $n$ decoding jobs using various splitting algorithms (\textsc{Naive-Split}, \textsc{Histogram-Split}, \textsc{Words-Split}, and \textsc{Times-Split}).}
\label{fig:maxspeed}
\end{figure*}

\begin{figure*}
\centering
\subfloat[Decoding times in \textbf{seconds} for decoder configured using a 5-gram language model.]{
\input{ngram/ngram.max-min-table.tex}
} \\
%\caption{\fontspec{TeX Gyre Pagella}Decoding times in \textbf{seconds} for the fastest (min) and slowest (max) decoding jobs (for a phrase-based decoder configured using a 5-gram language model) when a translation task is split into $n$ decoding jobs. \textit{Italics} indicate balanced task times. \textbf{Bold} indicates fastest max time at that split.}
%\label{fig:minmaxspeed}
%\end{figure*}
%
%\begin{figure*}
\subfloat[Decoding times in \textbf{hours} for decoder configured using a syntactic language model (Schwartz et al., 2011) addition to a 5-gram language model.]{
\input{hhmm/hhmm.max-min-table.tex}
}
%\caption{\fontspec{TeX Gyre Pagella}Decoding times in \textbf{hours} for the fastest (min) and slowest (max) decoding jobs (for a phrase-based decoder configured using a syntactic language model (Schwartz et al., 2011) in addition to a 5-gram language model) when a translation task is split into $n$ decoding jobs. \textit{Italics} indicate balanced task times. \textbf{Bold} indicates fastest max time at that split.}
\caption{\fontspec{TeX Gyre Pagella}Decoding times for the fastest (min) and slowest (max) decoding jobs when a translation task is split into $n$ decoding jobs. \textbf{Bold} indicates fastest max time at that split. \textit{Italics} indicate balanced task times, corresponding to zero slack time (see Figure \ref{fig:slack}).}
%\label{fig:minmaxspeedhhmm}
\label{fig:minmaxspeed}
\end{figure*}


\begin{figure*}
\centering
%%%%%%%%%%%%%%%%%%%%%%% 
% Begin subfloat
%%%%%%%%%%%%%%%%%%%%%%%
\subfloat[Slack \textbf{CPU-Seconds} for decoder configured using a 5-gram language model.]{
\begin{tikzpicture}
\begin{axis}[
xmode=log,
ymode=normal,
xtick pos=left,
xtick=data,
ytick=data,
log basis x=2,
xticklabels={2,4,8,16,32,64,128,256,512},
scaled y ticks=false,
ytick={2000,1800,1600,1400,1200,1000,800,600,400,200,100},
tick label style={font=\tiny},
xlabel=Split Size ($n$),
ylabel=Slack CPU-Seconds,
ymin=0,
legend pos=north west,
%ybar=0pt,
%bar width=3pt,
bar shift=0pt,
width=13cm,
height=7cm,
ybar,
bar width=5pt,
cycle list={fill=gray!15!blue!15,fill=gray!50!orange!50,fill=gray!70!green!70,fill=gray!100}
]
%
\input{ngram/ngram.naive-slack_times}
\input{ngram/ngram.histogram-slack_times}
\input{ngram/ngram.words-slack_times}
\input{ngram/ngram.time-slack_times}
%
\legend{{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 1: \textsc{Naive-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 2: \textsc{Histogram-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 3: \textsc{Words-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 4: \textsc{Times-Split}}}
\end{axis}
\end{tikzpicture}
}
%%%%%%%%%%%%%%%%%%%%%%% 
% End subfloat
%%%%%%%%%%%%%%%%%%%%%%%
%
\qquad
%
%%%%%%%%%%%%%%%%%%%%%%% 
% Begin subfloat
%%%%%%%%%%%%%%%%%%%%%%%
\subfloat[Slack \textbf{CPU-Hours} for decoder configured using a syntactic language model (Schwartz et al., 2011) in addition to a 5-gram language model.]{
\begin{tikzpicture}
\begin{axis}[
xmode=log,
ymode=normal,
xtick pos=left,
xtick=data,
ytick=data,
log basis x=2,
xticklabels={2,4,8,16,32,64,128,256,512},
ytick={3000,2500,2000,1500,1000,750,500,250,100},
tick label style={font=\tiny},
xlabel=Split Size ($n$),
ylabel=Slack CPU-Hours,
ymin=0,
legend pos=north west,
%ybar=0pt,
%bar width=3pt,
bar shift=0pt,
width=13cm,
height=7cm,
ybar,
bar width=5pt,
cycle list={fill=gray!15!blue!15,fill=gray!50!orange!50,fill=gray!70!green!70,fill=gray!100}
]
%
\input{hhmm/hhmm.naive-slack_times}
\input{hhmm/hhmm.histogram-slack_times}
\input{hhmm/hhmm.words-slack_times}
\input{hhmm/hhmm.time-slack_times}
%
\legend{{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 1: \textsc{Naive-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 2: \textsc{Histogram-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 3: \textsc{Words-Split}},{\fontspec{TeX Gyre Pagella}\footnotesize Algorithm 4: \textsc{Times-Split}}}
\end{axis}
\end{tikzpicture}
}
%%%%%%%%%%%%%%%%%%%%%%% 
% End subfloat
%%%%%%%%%%%%%%%%%%%%%%%
\caption{Cumulative slack CPU time for $n$ processing cores when processing a parallel translation task split into $n$ jobs using various splitting algorithms. Slack CPU time is caused when some jobs finish before others. Zero slack time indicates conditions where all jobs complete simultaneously.}
\label{fig:slack}
\end{figure*}


%\vspace{-0.2cm}
\section{Conclusion}
%\vspace{-0.1cm}
%The task of translation involves translating a source language document into a target language. 
%
While statistical translation models could, in theory, condition on previously translated sentences, in practice virtually no widely used models do so.
%
%The task of translating a document is therefore embarrassingly parallel.
Translation is therefore embarrassingly parallel ---
%
a document to be translated can be split into $n$ parts, with each part translated independently a different computational node.

While such splitting is commonly performed, a suboptimal naive splitting technique (Algorithm \ref{alg:naive}) is used by all translation software of which we are aware. 
%
In this work we have presented three more effective corpus splitting algorithms (Algorithms \ref{alg:histogram}, \ref{alg:words} and \ref{alg:times}), 
%the Moses decoding scripts,
%{\tt moses-parallel.pl},
% 
enabling substantial speed-ups in parallel decoding time at no additional cost.

We observe that while Algorithm \ref{alg:histogram} fails to improve over Algorithm \ref{alg:naive} for a standard Moses configuration for small values of $n$, for values of $n>8$, and for all values of $n$ using the slow syntactic language model, Algorithm \ref{alg:histogram} represents a clear improvement. Results for Algorithm \ref{alg:words} show further speedups over Algorithms \ref{alg:naive} and \ref{alg:histogram} in most configurations. Algorithm \ref{alg:times} is the clear winner, nearly eliminating slack time in many cases.

%In Figure \ref{fig:minmaxspeed}a, we observe that the maximum runtimes using Algorithm \ref{alg:histogram} fail to improve over the runtimes using Algorithm \ref{alg:naive} for a standard Moses configuration for small values of $n$. But for values of $n>8$, and for all values of $n$ using the slow syntactic language model, Figure \ref{fig:minmaxspeed}b shows that Algorithm \ref{alg:histogram} results in significant decreases in total decoding time over the naive Algorithm \ref{alg:naive}.
%
%Results for Algorithm \ref{alg:words} show substantial speedups over Algorithms \ref{alg:naive} and \ref{alg:histogram} when using the slower decoder configuration. Similar speedups are seen where $n>8$ for the faster configuration.
%
%This technique results in speedups under all conditions (Figure \ref{fig:minmaxspeed}). In nearly all conditions, the speedup is substantial over the baseline. 
%
%Figure \ref{fig:slack} shows that slack time is at or near zero in all cases where $n<256$.

While the most effective algorithm (Algorithm \ref{alg:times}) requires per-sentence decode times from previous decodes, in most realistic settings, Algorithm \ref{alg:words} provides much of the benefit of Algorithm \ref{alg:times} in terms of decreased computational slack time while requiring little changes to existing decoding scripts which use the naive Algorithm \ref{alg:naive}.

%The use of Algorithm \ref{alg:words} in the first MERT iteration, and \ref{alg:times} in subsequent iterations.

Implementations in Ruby and Java of all four splitting algorithms are provided at \url{http://github.com/dowobeha/balance-corpus}.





% \begin{algorithm}
% \caption{Find the index of the smallest array element}
% \begin{algorithmic}
% \Function{Least}{array}
% \State best.value $\gets \infty$
% \State best.index $\gets 0$
% \For $i \gets 0 \ldots \mbox{array.length}-1$
% \If {array[$i$] $<$ best.value}
% \State best.value = array[$i$]
% \State best.index = $i$
% \EndIf
% \EndFor
% \State \textbf{return} best.index
% \EndFunction
% \end{algorithmic}
% \end{algorithm}




%\section{Conclusion}






%\todo[inline]{Describe results. \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ \\ \ }






\clearpage
\thanksnostar{Opinions, interpretations, conclusions, and recommendations are those of the authors and are not necessarily endorsed by the United States Air Force. Cleared for public release on 19 Jan 2011. Originator reference number RH-11-107802. Case number 88ABW-2011-0185. Thanks to Grant Erdmann and Tim Anderson, and to the anonymous reviewers.}

\bibliography{bibliography}

\end{document}
